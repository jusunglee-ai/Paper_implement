{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UaQVizZ_ev9V"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import math\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "# sklearn\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, src_embed, tgt_embed, encoder, decoder, generator):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.generator = generator\n",
        "\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "\n",
        "    def decode(self, tgt, encoder_out, tgt_mask, src_tgt_mask):\n",
        "        return self.decoder(self.tgt_embed(tgt), encoder_out, tgt_mask, src_tgt_mask)\n",
        "\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        tgt_mask = self.make_tgt_mask(tgt)\n",
        "        src_tgt_mask = self.make_src_tgt_mask(src, tgt)\n",
        "        encoder_out = self.encode(src, src_mask)\n",
        "        decoder_out = self.decode(tgt, encoder_out, tgt_mask, src_tgt_mask)\n",
        "        out = self.generator(decoder_out)\n",
        "        #Transformer의 디코더는 입력을 처리하고 hidden state(많은 정보가 담긴 벡터)인 출력을 생성함\n",
        "        #그렇기 때문에 이러한 hidden state는 단어를 예측하는데 유용하지 않음\n",
        "        #그래서 이를 가져와서 점수 벡터에 매핑 하는 간단한 선형레이어임\n",
        "        #여기서 각 점수는 어휘의 단어에 해당함\n",
        "        out = F.log_softmax(out, dim=-1)\n",
        "        #마지막에서 softmax의 차원을 -1로 설정해주는데 그 이유는 dimension인\n",
        "        #len(vocab)에 대한 확률값을 구해야 하기 때문이다.\n",
        "        return out, decoder_out\n",
        "\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        pad_mask = self.make_pad_mask(src, src)\n",
        "        return pad_mask\n",
        "\n",
        "\n",
        "    def make_tgt_mask(self, tgt):\n",
        "        pad_mask = self.make_pad_mask(tgt, tgt)\n",
        "        seq_mask = self.make_subsequent_mask(tgt, tgt)\n",
        "        mask = pad_mask & seq_mask\n",
        "        return pad_mask & seq_mask\n",
        "\n",
        "\n",
        "    def make_src_tgt_mask(self, src, tgt):\n",
        "        pad_mask = self.make_pad_mask(tgt, src)\n",
        "        return pad_mask\n",
        "\n",
        "\n",
        "    def make_pad_mask(self, query, key, pad_idx=1):\n",
        "        # query: (n_batch, query_seq_len)\n",
        "        # key: (n_batch, key_seq_len)\n",
        "        query_seq_len, key_seq_len = query.size(1), key.size(1)\n",
        "\n",
        "        key_mask = key.ne(pad_idx).unsqueeze(1).unsqueeze(2)  # (n_batch, 1, 1, key_seq_len)\n",
        "        key_mask = key_mask.repeat(1, 1, query_seq_len, 1)    # (n_batch, 1, query_seq_len, key_seq_len)\n",
        "\n",
        "        query_mask = query.ne(pad_idx).unsqueeze(1).unsqueeze(3)  # (n_batch, 1, query_seq_len, 1)\n",
        "        query_mask = query_mask.repeat(1, 1, 1, key_seq_len)  # (n_batch, 1, query_seq_len, key_seq_len)\n",
        "\n",
        "        mask = key_mask & query_mask\n",
        "        mask.requires_grad = False\n",
        "        return mask\n",
        "\n",
        "\n",
        "    def make_subsequent_mask(self, query, key):\n",
        "        query_seq_len, key_seq_len = query.size(1), key.size(1)\n",
        "\n",
        "        tril = np.tril(np.ones((query_seq_len, key_seq_len)), k=0).astype('uint8') # lower triangle without diagonal\n",
        "        #np.tril()을 이용해서 lower triangle을 생성함. query_seq_len과 key_seq_len이 모두 10일 때\n",
        "        #대각선을 기준으로 하여 1과 0으로만 구성되어 있는 삼각형이 2개 생성됨\n",
        "        mask = torch.tensor(tril, dtype=torch.bool, requires_grad=False, device=query.device)\n",
        "\n",
        "        return mask\n"
      ],
      "metadata": {
        "id": "8rdsqe3Jfuz6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "YmteI_ZcbKbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0번째 토큰의 경우 자기 자신밖에 볼 수 없으며, 1~n번째 토큰은 0으로 가려져있고.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1번째 토큰은 0~1번째 토큰밖에 보지 못합니다, 또한 나머지 2번째부터 n번째 토큰은 보지 못함."
      ],
      "metadata": {
        "id": "BCTkPw5lbR_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder_block, n_layer, norm):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.n_layer = n_layer\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(encoder_block)\n",
        "        for _ in range(self.n_layer)])\n",
        "        self.norm = norm\n",
        "#copy.deepcopy는 input으로 들어가는 개체의 전체 복사본을 만드는데 사용됨. 이는 input 개체에 대한\n",
        "#참조를 복사하는 대신 개체의 새 인스턴스가 생성됨을 의미함.\n",
        "#즉 주소를 참조해서 하는게 아니라 원본 자체를 복사하여, 복사본을 수정하더라도 주소값을 참조하지 않기\n",
        "#때문에, 원본은 그대로 보존되고 복사본만 수정이 된다.\n",
        "    def forward(self, src, src_mask):\n",
        "        out = src\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, src_mask)\n",
        "        out = self.norm(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "R7-EgyIagqZm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, self_attention, position_ff, norm, dr_rate=0):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.self_attention = self_attention\n",
        "        self.residual1 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
        "        self.position_ff = position_ff\n",
        "        self.residual2 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
        "\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        out = src\n",
        "        out = self.residual1(out, lambda out: self.self_attention(query=out, key=out, value=out, mask=src_mask))\n",
        "        out = self.residual2(out, self.position_ff)\n",
        "        return out"
      ],
      "metadata": {
        "id": "jH4dEMK4hY2a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, h, qkv_fc, out_fc, dr_rate=0):\n",
        "        super(MultiHeadAttentionLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.h = h\n",
        "        self.q_fc = copy.deepcopy(qkv_fc) # (d_embed, d_model)\n",
        "        self.k_fc = copy.deepcopy(qkv_fc) # (d_embed, d_model)\n",
        "        self.v_fc = copy.deepcopy(qkv_fc) # (d_embed, d_model)\n",
        "        self.out_fc = out_fc              # (d_model, d_embed)\n",
        "        self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "\n",
        "    def calculate_attention(self, query, key, value, mask):\n",
        "        # query, key, value: (n_batch, h, seq_len, d_k)\n",
        "        # mask: (n_batch, seq_len, seq_len)\n",
        "        d_k = key.shape[-1]\n",
        "        attention_score = torch.matmul(query, key.transpose(-2, -1)) # Q x K^T, (n_batch, h, seq_len, seq_len)\n",
        "        attention_score = attention_score / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            attention_score = attention_score.masked_fill(mask==0, -1e9)\n",
        "        attention_prob = F.softmax(attention_score, dim=-1) # (n_batch, h, seq_len, seq_len)\n",
        "        attention_prob = self.dropout(attention_prob)\n",
        "        out = torch.matmul(attention_prob, value) # Attention score X V\n",
        "        return out\n",
        "\n",
        "\n",
        "    def forward(self, *args, query, key, value, mask=None):\n",
        "        # query, key, value: (n_batch, seq_len, d_embed)\n",
        "        # mask: (n_batch, seq_len, seq_len)\n",
        "        # return value: (n_batch, h, seq_len, d_k)\n",
        "        n_batch = query.size(0)\n",
        "\n",
        "        def transform(x, fc): # (n_batch, seq_len, d_embed)\n",
        "            out = fc(x)       # (n_batch, seq_len, d_model)\n",
        "            out = out.view(n_batch, -1, self.h, self.d_model//self.h) # (n_batch, seq_len, h, d_k)\n",
        "            #view 메서드의 경우 multi head attention을 수행하기 위해 모델 차원을\n",
        "            #multi head로 분리하도록 tensor를 재구성함.\n",
        "            #view 메서드는 데이터를 변경하지 않고 tensor의 모양을 변경하는데 사용 됨.\n",
        "            out = out.transpose(1, 2) # (n_batch, h, seq_len, d_k)\n",
        "            return out\n",
        "\n",
        "        query = transform(query, self.q_fc) # (n_batch, h, seq_len, d_k)\n",
        "        key = transform(key, self.k_fc)       # (n_batch, h, seq_len, d_k)\n",
        "        value = transform(value, self.v_fc) # (n_batch, h, seq_len, d_k)\n",
        "\n",
        "        out = self.calculate_attention(query, key, value, mask) # (n_batch, h, seq_len, d_k)\n",
        "        out = out.transpose(1, 2) # (n_batch, seq_len, h, d_k)\n",
        "        out = out.contiguous().view(n_batch, -1, self.d_model) # (n_batch, seq_len, d_model)\n",
        "        out = self.out_fc(out) # (n_batch, seq_len, d_embed)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "_lUzhjpElF_3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFeedForwardLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, fc1, fc2, dr_rate=0):\n",
        "        super(PositionWiseFeedForwardLayer, self).__init__()\n",
        "        self.fc1 = fc1   # (d_embed, d_ff)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=dr_rate)\n",
        "        self.fc2 = fc2 # (d_ff, d_embed)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Xbd-ZsTGY546"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConnectionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, norm, dr_rate=0):\n",
        "        super(ResidualConnectionLayer, self).__init__()\n",
        "        self.norm = norm\n",
        "        self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x, sub_layer):\n",
        "        out = x\n",
        "        out = self.norm(out)\n",
        "        out = sub_layer(out)\n",
        "        out = self.dropout(out)\n",
        "        out = out + x\n",
        "        return out"
      ],
      "metadata": {
        "id": "LxrI_aotZUqQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, decoder_block, n_layer, norm):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.n_layer = n_layer\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(decoder_block) for _ in range(self.n_layer)])\n",
        "        self.norm = norm\n",
        "\n",
        "\n",
        "    def forward(self, tgt, encoder_out, tgt_mask, src_tgt_mask):\n",
        "        out = tgt\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, encoder_out, tgt_mask, src_tgt_mask)\n",
        "        out = self.norm(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "A04Xx13cg0D3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, self_attention, cross_attention, position_ff, norm, dr_rate=0):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.self_attention = self_attention\n",
        "        self.residual1 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
        "        self.cross_attention = cross_attention\n",
        "        self.residual2 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
        "        self.position_ff = position_ff\n",
        "        self.residual3 = ResidualConnectionLayer(copy.deepcopy(norm), dr_rate)\n",
        "\n",
        "\n",
        "    def forward(self, tgt, encoder_out, tgt_mask, src_tgt_mask):\n",
        "        out = tgt\n",
        "        out = self.residual1(out, lambda out: self.self_attention(query=out, key=out, value=out, mask=tgt_mask))\n",
        "        out = self.residual2(out, lambda out: self.cross_attention(query=out, key=encoder_out, value=encoder_out, mask=src_tgt_mask))\n",
        "        out = self.residual3(out, self.position_ff)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fn0vh1kHnPOp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, token_embed, pos_embed, dr_rate=0):\n",
        "        super(TransformerEmbedding, self).__init__()\n",
        "        self.embedding = nn.Sequential(token_embed, pos_embed)\n",
        "        self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        out = self.embedding(out)\n",
        "        out = self.dropout(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "65eH8Tsio4XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_embed, vocab_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
        "        self.d_embed = d_embed\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embedding(x) * math.sqrt(self.d_embed)\n",
        "        return out"
      ],
      "metadata": {
        "id": "IkGAKAF00Zp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_embed, max_len=256, device=torch.device(\"cpu\")):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        encoding = torch.zeros(max_len, d_embed)\n",
        "        encoding.requires_grad = False\n",
        "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_embed, 2) * -(math.log(10000.0) / d_embed))\n",
        "        encoding[:, 0::2] = torch.sin(position * div_term)\n",
        "        encoding[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.encoding = encoding.unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, seq_len, _ = x.size()\n",
        "        pos_embed = self.encoding[:, :seq_len, :]\n",
        "        out = x + pos_embed\n",
        "        return out"
      ],
      "metadata": {
        "id": "LCpz61BF1Egn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(src_vocab_size,\n",
        "                tgt_vocab_size,\n",
        "                device=torch.device(\"cpu\"),\n",
        "                max_len = 256,\n",
        "                d_embed = 512,\n",
        "                n_layer = 6,\n",
        "                d_model = 512,\n",
        "                h = 8,\n",
        "                d_ff = 2048,\n",
        "                dr_rate = 0.1,\n",
        "                norm_eps = 1e-5):\n",
        "    import copy\n",
        "    copy = copy.deepcopy\n",
        "\n",
        "    src_token_embed = TokenEmbedding(\n",
        "                                     d_embed = d_embed,\n",
        "                                     vocab_size = src_vocab_size)\n",
        "    tgt_token_embed = TokenEmbedding(\n",
        "                                     d_embed = d_embed,\n",
        "                                     vocab_size = tgt_vocab_size)\n",
        "    pos_embed = PositionalEncoding(\n",
        "                                   d_embed = d_embed,\n",
        "                                   max_len = max_len,\n",
        "                                   device = device)\n",
        "\n",
        "    src_embed = TransformerEmbedding(\n",
        "                                     token_embed = src_token_embed,\n",
        "                                     pos_embed = copy(pos_embed),\n",
        "                                     dr_rate = dr_rate)\n",
        "    tgt_embed = TransformerEmbedding(\n",
        "                                     token_embed = tgt_token_embed,\n",
        "                                     pos_embed = copy(pos_embed),\n",
        "                                     dr_rate = dr_rate)\n",
        "\n",
        "    attention = MultiHeadAttentionLayer(\n",
        "                                        d_model = d_model,\n",
        "                                        h = h,\n",
        "                                        qkv_fc = nn.Linear(d_embed, d_model),\n",
        "                                        out_fc = nn.Linear(d_model, d_embed),\n",
        "                                        dr_rate = dr_rate)\n",
        "    position_ff = PositionWiseFeedForwardLayer(\n",
        "                                               fc1 = nn.Linear(d_embed, d_ff),\n",
        "                                               fc2 = nn.Linear(d_ff, d_embed),\n",
        "                                               dr_rate = dr_rate)\n",
        "    norm = nn.LayerNorm(d_embed, eps = norm_eps)\n",
        "\n",
        "    encoder_block = EncoderBlock(\n",
        "                                 self_attention = copy(attention),\n",
        "                                 position_ff = copy(position_ff),\n",
        "                                 norm = copy(norm),\n",
        "                                 dr_rate = dr_rate)\n",
        "    decoder_block = DecoderBlock(\n",
        "                                 self_attention = copy(attention),\n",
        "                                 cross_attention = copy(attention),\n",
        "                                 position_ff = copy(position_ff),\n",
        "                                 norm = copy(norm),\n",
        "                                 dr_rate = dr_rate)\n",
        "\n",
        "    encoder = Encoder(\n",
        "                      encoder_block = encoder_block,\n",
        "                      n_layer = n_layer,\n",
        "                      norm = copy(norm))\n",
        "    decoder = Decoder(\n",
        "                      decoder_block = decoder_block,\n",
        "                      n_layer = n_layer,\n",
        "                      norm = copy(norm))\n",
        "    generator = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "    model = Transformer(\n",
        "                        src_embed = src_embed,\n",
        "                        tgt_embed = tgt_embed,\n",
        "                        encoder = encoder,\n",
        "                        decoder = decoder,\n",
        "                        generator = generator).to(device)\n",
        "    model.device = device\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "f5qntYu0ra-H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}